{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "452cdeef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "allg: {'model_folder': 'models', 'use_model_file': '', 'sequence_length': 60, 'train_epochs': 10000, 'batch_size': 32, 'validation_split': 0.2, 'early_stopping_patience': 5, 'feature_scaling': True, 'use_dropout': True, 'dropout_rate': 0.2, 'loss_function': 'binary_crossentropy', 'optimizer': 'adam', 'debug_mode': True}\n",
      "online: {'symbols': ['BTC', 'ETH', 'SOL'], 'currencies': ['USDT', 'USDT', 'USDT'], 'interval': '1m', 'poll_seconds': 10, 'max_live_train_minutes': 60}\n",
      "offline: {'enabled': True, 'csv_folder': 'csv/binance', 'csv_file': 'BTCUSDT-1m-1y-binance-2025-09-12_22-40-01.csv'}\n",
      "balance_settings: {'use_simulation': True, 'initial_balance': 1000, 'save_on_profit_percent': 50, 'game_over_threshold': 0, 'balance_reward_factor': 1.0, 'retrain_from_best': True}\n",
      "training_opts: {'use_weighting': True, 'punish_on_wrong': True, 'predict_confidence': True, 'log_transactions': True}\n"
     ]
    }
   ],
   "source": [
    "import os, json, time, requests\n",
    "import numpy as np, pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from datetime import datetime\n",
    "\n",
    "# -------------------------------\n",
    "# Settings laden / default erstellen\n",
    "# -------------------------------\n",
    "settings_file = \"settings.json\"\n",
    "if not os.path.exists(settings_file):\n",
    "    default_settings = {\n",
    "        \"allgemein_settings\": {\n",
    "            \"model_folder\": \"models\",\n",
    "            \"use_model_file\": \"Heusc_v0.3_20250913_024701.keras\",\n",
    "            \"sequence_length\": 60,\n",
    "            \"train_epochs\": 10000,\n",
    "            \"batch_size\": 32,\n",
    "            \"validation_split\": 0.2,\n",
    "            \"early_stopping_patience\": 5,\n",
    "            \"feature_scaling\": True,\n",
    "            \"use_dropout\": True,\n",
    "            \"dropout_rate\": 0.2,\n",
    "            \"loss_function\": \"binary_crossentropy\",\n",
    "            \"optimizer\": \"adam\",\n",
    "            \"debug_mode\": True\n",
    "        },\n",
    "        \"offline\": {\n",
    "            \"enabled\": True,\n",
    "            \"csv_folder\": \"csv/binance\",\n",
    "            \"csv_file\": \"BTCUSDT-1m-1y-binance-2025-09-12_22-40-01.csv\"\n",
    "        },\n",
    "        \"online\": {\n",
    "            \"symbols\": [\"BTC\",\"ETH\",\"SOL\"],\n",
    "            \"currencies\": [\"USDT\",\"USDT\",\"USDT\"],\n",
    "            \"interval\": \"1m\",\n",
    "            \"poll_seconds\": 10,\n",
    "            \"max_live_train_minutes\": 60\n",
    "        },\n",
    "        \"balance\": {\n",
    "            \"use_simulation\": True,\n",
    "            \"initial_balance\": 1000,\n",
    "            \"save_on_profit_percent\": 50,\n",
    "            \"game_over_threshold\": 0,\n",
    "            \"balance_reward_factor\": 1.0,\n",
    "            \"retrain_from_best\": True\n",
    "        },\n",
    "        \"training_options\": {\n",
    "            \"use_weighting\": True,\n",
    "            \"punish_on_wrong\": True,\n",
    "            \"predict_confidence\": True,\n",
    "            \"log_transactions\": True,\n",
    "            \"continual_learning\": True,\n",
    "            \"transfer_learning\": True,\n",
    "            \"ensemble_enabled\": True\n",
    "        }\n",
    "    }\n",
    "    with open(settings_file,\"w\") as f:\n",
    "        json.dump(default_settings, f, indent=4)\n",
    "\n",
    "with open(settings_file,\"r\") as f:\n",
    "    settings = json.load(f)\n",
    "\n",
    "allg = settings['allgemein_settings']\n",
    "online = settings['online']\n",
    "offline = settings['offline']\n",
    "balance_settings = settings['balance']\n",
    "training_options = settings['training_options']\n",
    "\n",
    "print(f\"allg: {allg}\")\n",
    "print(f\"online: {online}\")\n",
    "print(f\"offline: {offline}\")\n",
    "print(f\"balance_settings: {balance_settings}\")\n",
    "print(f\"training_opts: {training_opts}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2301cbd9",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "File format not supported: filepath=models\\. Keras 3 only supports V3 `.keras` files and legacy H5 format files (`.h5` extension). Note that the legacy SavedModel format is not supported by `load_model()` in Keras 3. In order to reload a TensorFlow SavedModel as an inference-only layer in Keras 3, use `keras.layers.TFSMLayer(models\\, call_endpoint='serving_default')` (note that your `call_endpoint` might have a different name).",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[49]\u001b[39m\u001b[32m, line 22\u001b[39m\n\u001b[32m     20\u001b[39m \u001b[38;5;66;03m# Lade Modell\u001b[39;00m\n\u001b[32m     21\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m os.path.exists(model_path):\n\u001b[32m---> \u001b[39m\u001b[32m22\u001b[39m     model = \u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     23\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mModel geladen: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     24\u001b[39m     \u001b[38;5;66;03m# Lade Transaktionen\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\keras\\src\\saving\\saving_api.py:209\u001b[39m, in \u001b[36mload_model\u001b[39m\u001b[34m(filepath, custom_objects, compile, safe_mode)\u001b[39m\n\u001b[32m    203\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    204\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFile not found: filepath=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilepath\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    205\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mPlease ensure the file is an accessible `.keras` \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    206\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mzip file.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    207\u001b[39m     )\n\u001b[32m    208\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m209\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    210\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFile format not supported: filepath=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilepath\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    211\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mKeras 3 only supports V3 `.keras` files and \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    212\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mlegacy H5 format files (`.h5` extension). \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    213\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mNote that the legacy SavedModel format is not \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    214\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33msupported by `load_model()` in Keras 3. In \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    215\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33morder to reload a TensorFlow SavedModel as an \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    216\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33minference-only layer in Keras 3, use \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    217\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m`keras.layers.TFSMLayer(\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    218\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilepath\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, call_endpoint=\u001b[39m\u001b[33m'\u001b[39m\u001b[33mserving_default\u001b[39m\u001b[33m'\u001b[39m\u001b[33m)` \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    219\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m(note that your `call_endpoint` \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    220\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mmight have a different name).\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    221\u001b[39m     )\n",
      "\u001b[31mValueError\u001b[39m: File format not supported: filepath=models\\. Keras 3 only supports V3 `.keras` files and legacy H5 format files (`.h5` extension). Note that the legacy SavedModel format is not supported by `load_model()` in Keras 3. In order to reload a TensorFlow SavedModel as an inference-only layer in Keras 3, use `keras.layers.TFSMLayer(models\\, call_endpoint='serving_default')` (note that your `call_endpoint` might have a different name)."
     ]
    }
   ],
   "source": [
    "# -------------------------------\n",
    "# Modell erstellen oder laden\n",
    "# -------------------------------\n",
    "def create_model(input_dim=7):\n",
    "    model = Sequential([\n",
    "        Dense(64, activation=\"relu\", input_shape=(input_dim,)),\n",
    "        Dropout(allg.get(\"dropout_rate\",0.2)),\n",
    "        Dense(32, activation=\"relu\"),\n",
    "        Dropout(allg.get(\"dropout_rate\",0.2)),\n",
    "        Dense(1, activation=\"sigmoid\")\n",
    "    ])\n",
    "    model.compile(optimizer=Adam(0.001), loss=allg.get(\"loss_function\",\"binary_crossentropy\"), metrics=[\"accuracy\"])\n",
    "    return model\n",
    "\n",
    "model_folder = allg[\"model_folder\"]\n",
    "os.makedirs(model_folder, exist_ok=True)\n",
    "model_path = os.path.join(model_folder, allg[\"use_model_file\"])\n",
    "json_path = model_path.replace(\".keras\",\".json\")\n",
    "\n",
    "# Lade Modell\n",
    "if os.path.exists(model_path):\n",
    "    model = load_model(model_path)\n",
    "    print(f\"Model geladen: {model_path}\")\n",
    "    # Lade Transaktionen\n",
    "    if os.path.exists(json_path):\n",
    "        with open(json_path,\"r\") as f:\n",
    "            model_data = json.load(f)\n",
    "        balance = model_data.get(\"balance\", balance_settings[\"initial_balance\"])\n",
    "        transactions = model_data.get(\"transactions\", [])\n",
    "    else:\n",
    "        balance = balance_settings[\"initial_balance\"]\n",
    "        transactions = []\n",
    "else:\n",
    "    model = create_model()\n",
    "    balance = balance_settings[\"initial_balance\"]\n",
    "    transactions = []\n",
    "    print(\"Neues Modell erstellt.\")\n",
    "\n",
    "# Scaler\n",
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05fa4db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "# Funktion zum Speichern der Transaktionen\n",
    "# -------------------------------\n",
    "def save_model_json(balance, transactions, model_path):\n",
    "    json_path = os.path.join(\n",
    "        allg[\"model_folder\"], \n",
    "        f\"{os.path.splitext(os.path.basename(model_path))[0]}_transactions.json\"\n",
    "    )\n",
    "    \n",
    "    data = {\n",
    "        \"model\": os.path.basename(model_path),\n",
    "        \"created\": str(datetime.now()),\n",
    "        \"balance\": balance,\n",
    "        \"transactions\": transactions\n",
    "    }\n",
    "\n",
    "    with open(json_path,\"w\") as f:\n",
    "        json.dump(data, f, indent=4)\n",
    "    \n",
    "    print(f\"Transactions JSON gespeichert → {json_path}\")\n",
    "    return json_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb9b88b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "# Offline Training & Trade Logging\n",
    "# -------------------------------\n",
    "def offline_train(csv_file):\n",
    "    df = pd.read_csv(csv_file)\n",
    "\n",
    "    # Features + Label\n",
    "    X = df[[\"open\",\"high\",\"low\",\"close\",\"prev_close\",\"current_close\",\"volume\"]].values\n",
    "    y = (df[\"color\"].str.lower() == \"green\").astype(int).values\n",
    "\n",
    "    # Scaling\n",
    "    X = scaler.fit_transform(X)\n",
    "\n",
    "    # Balance initialisieren\n",
    "    balance = balance_settings.get(\"initial_balance\", 1000)\n",
    "    transactions = []\n",
    "\n",
    "    for idx,row in df.iterrows():\n",
    "        input_X = np.array([X[idx]])\n",
    "        y_pred_prob = model.predict(input_X, verbose=0).flatten()[0]\n",
    "        pred_label = \"green\" if y_pred_prob>0.5 else \"red\"\n",
    "        true_label = \"green\" if row[\"color\"].lower() == \"green\" else \"red\"\n",
    "\n",
    "        # Trade-Logik: Investieren\n",
    "        invested_balance = min(balance, 100)  # Beispiel: max 100 pro Trade\n",
    "        entry_price = row[\"prev_close\"]\n",
    "        exit_price = row[\"close\"]\n",
    "\n",
    "        # Profitberechnung: long wenn prediction green, short wenn red\n",
    "        profit = (exit_price - entry_price) * (1 if pred_label==\"green\" else -1)\n",
    "        profit_percent = (profit / invested_balance) * 100 if invested_balance>0 else 0\n",
    "        balance += profit\n",
    "\n",
    "        transactions.append({\n",
    "            \"entry_time\": str(row[\"timestamp\"]),\n",
    "            \"exit_time\": str(row[\"timestamp\"]),\n",
    "            \"symbol\": row.get(\"symbol\",\"BTCUSDT\"),\n",
    "            \"invested_balance\": invested_balance,\n",
    "            \"profit_percent\": profit_percent,\n",
    "            \"balance_after\": balance,\n",
    "            \"predicted\": pred_label,\n",
    "            \"actual\": true_label,\n",
    "            \"profit\": float(profit),\n",
    "            \"confidence\": {\"green\": float(y_pred_prob), \"red\": float(1-y_pred_prob)}\n",
    "        })\n",
    "\n",
    "        # Optional: eine Epoche Training auf einzelne Candle\n",
    "        model.fit(input_X, np.array([1 if true_label==\"green\" else 0]), epochs=1, verbose=0)\n",
    "\n",
    "    # Modell speichern\n",
    "    model.save(model_path)\n",
    "    print(f\"Offline Training abgeschlossen → {model_path}\")\n",
    "\n",
    "    # JSON speichern\n",
    "    json_path = os.path.join(allg[\"model_folder\"], f\"{os.path.splitext(allg['use_model_file'])[0]}_transactions.json\")\n",
    "    with open(json_path, \"w\") as f:\n",
    "        json.dump({\n",
    "            \"model\": os.path.basename(model_path),\n",
    "            \"created\": str(datetime.now()),\n",
    "            \"balance\": balance,\n",
    "            \"transactions\": transactions\n",
    "        }, f, indent=4)\n",
    "    print(f\"Transactions JSON gespeichert → {json_path}\")\n",
    "\n",
    "    # CSV speichern\n",
    "    csv_path = os.path.join(allg[\"model_folder\"], f\"{os.path.splitext(allg['use_model_file'])[0]}_transactions.csv\")\n",
    "    pd.DataFrame(transactions).to_csv(csv_path, index=False)\n",
    "    print(f\"Transactions CSV gespeichert → {csv_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90c94fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "# CSV-Export für Analyse\n",
    "# -------------------------------\n",
    "def export_transactions_csv(csv_file=None):\n",
    "    if csv_file is None:\n",
    "        csv_file = json_path.replace(\".json\",\"_transactions.csv\")\n",
    "    pd.DataFrame(transactions).to_csv(csv_file,index=False)\n",
    "    print(f\"Transaktionen exportiert → {csv_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7dcd2ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "# Funktion zum Speichern der Transaktionen (JSON + CSV)\n",
    "# -------------------------------\n",
    "def save_transactions(balance, transactions, model_path):\n",
    "    base_name = os.path.splitext(os.path.basename(model_path))[0]\n",
    "    \n",
    "    # JSON speichern\n",
    "    json_path = os.path.join(allg[\"model_folder\"], f\"{base_name}_transactions.json\")\n",
    "    data = {\n",
    "        \"model\": os.path.basename(model_path),\n",
    "        \"created\": str(datetime.now()),\n",
    "        \"balance\": balance,\n",
    "        \"transactions\": transactions\n",
    "    }\n",
    "    with open(json_path, \"w\") as f:\n",
    "        json.dump(data, f, indent=4)\n",
    "    \n",
    "    # CSV speichern\n",
    "    csv_path = os.path.join(allg[\"model_folder\"], f\"{base_name}_transactions.csv\")\n",
    "    \n",
    "    # CSV Header\n",
    "    csv_columns = [\n",
    "        \"timestamp\", \"symbol\", \"open\", \"high\", \"low\", \"close\", \n",
    "        \"prev_close\", \"current_close\", \"volume\", \n",
    "        \"balance_invested\", \"profit\", \"predicted\", \"actual\", \n",
    "        \"confidence_green\", \"confidence_red\"\n",
    "    ]\n",
    "    \n",
    "    csv_rows = []\n",
    "    for t in transactions:\n",
    "        csv_rows.append({\n",
    "            \"timestamp\": t.get(\"timestamp\"),\n",
    "            \"symbol\": t.get(\"symbol\"),\n",
    "            \"open\": t.get(\"open\"),\n",
    "            \"high\": t.get(\"high\"),\n",
    "            \"low\": t.get(\"low\"),\n",
    "            \"close\": t.get(\"close\"),\n",
    "            \"prev_close\": t.get(\"prev_close\"),\n",
    "            \"current_close\": t.get(\"current_close\"),\n",
    "            \"volume\": t.get(\"volume\"),\n",
    "            \"balance_invested\": t.get(\"balance_invested\", 0),\n",
    "            \"profit\": t.get(\"profit\", 0),\n",
    "            \"predicted\": t.get(\"predicted\"),\n",
    "            \"actual\": t.get(\"actual\"),\n",
    "            \"confidence_green\": t.get(\"confidence\", {}).get(\"green\", 0),\n",
    "            \"confidence_red\": t.get(\"confidence\", {}).get(\"red\", 0)\n",
    "        })\n",
    "    \n",
    "    df_csv = pd.DataFrame(csv_rows, columns=csv_columns)\n",
    "    df_csv.to_csv(csv_path, index=False)\n",
    "    \n",
    "    print(f\"Transactions JSON gespeichert → {json_path}\")\n",
    "    print(f\"Transactions CSV gespeichert → {csv_path}\")\n",
    "    \n",
    "    return json_path, csv_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "222661c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_live_data(symbol=\"BTCUSDT\", interval=\"1m\"):\n",
    "    url = f\"http://127.0.0.1:5000/api/live?symbols={symbol}&source=binance&interval={interval}\"\n",
    "    r = requests.get(url)\n",
    "    if r.status_code == 200:\n",
    "        data = r.json()\n",
    "        if symbol in data:\n",
    "            # Single candle in einer Liste zurückgeben für Konsistenz mit Train-Data\n",
    "            return [data[symbol]]\n",
    "        else:\n",
    "            print(f\"Symbol {symbol} nicht gefunden in API-Response\")\n",
    "            return []\n",
    "    else:\n",
    "        print(\"Fehler beim Abrufen der Live-Daten\")\n",
    "        return []\n",
    "\n",
    "def fetch_train_data(symbol=\"BTCUSDT\", interval=\"1m\", period=\"7d\"):\n",
    "    url = f\"http://127.0.0.1:5000/api/train_mode?symbols={symbol}&source=binance&interval={interval}&period={period}\"\n",
    "    r = requests.get(url)\n",
    "    if r.status_code == 200:\n",
    "        data = r.json()\n",
    "        if symbol in data and \"history\" in data[symbol]:\n",
    "            return data[symbol][\"history\"]\n",
    "        else:\n",
    "            print(f\"Keine Historie gefunden für Symbol {symbol}\")\n",
    "            return []\n",
    "    else:\n",
    "        print(\"Fehler beim Abrufen der Trainings-Daten\")\n",
    "        return []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ace0f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Globale Variablen\n",
    "scaler = None\n",
    "model = None  # Dein trainiertes Keras/TensorFlow-Modell\n",
    "allg = {\"feature_scaling\": True}  # Features skalieren\n",
    "training_options = {\"punish_on_wrong\": True}  # Strafe für falsche Vorhersagen\n",
    "\n",
    "# -------------------------------\n",
    "# Fit Scaler auf Trainingsdaten (einmalig)\n",
    "# -------------------------------\n",
    "def fit_scaler_on_training_data(candle_data):\n",
    "    global scaler\n",
    "    if allg.get(\"feature_scaling\", False):\n",
    "        features = np.array([[c[\"open\"], c[\"high\"], c[\"low\"], c[\"close\"],\n",
    "                              c[\"prev_close\"], c[\"current_close\"], c[\"volume\"]]\n",
    "                             for c in candle_data])\n",
    "        scaler.fit(features)\n",
    "        print(\"Scaler erfolgreich gefittet!\")\n",
    "    else:\n",
    "        print(\"Feature Scaling ist deaktiviert, Scaler nicht benötigt.\")\n",
    "\n",
    "# -------------------------------\n",
    "# Prepare Transactions\n",
    "# -------------------------------\n",
    "def prepare_transactions(candle_data, balance, train_mode=False, invest_pct=0.1):\n",
    "    global scaler, model\n",
    "    transactions = []\n",
    "\n",
    "    if train_mode:\n",
    "        # Beim Offline-Training sollte der Scaler schon gefittet sein\n",
    "        if allg.get(\"feature_scaling\", False) and scaler is None:\n",
    "            fit_scaler_on_training_data(candle_data)\n",
    "\n",
    "    for candle in candle_data:\n",
    "        invested = balance * invest_pct\n",
    "\n",
    "        # Feature-Vektor\n",
    "        features = np.array([[candle[\"open\"], candle[\"high\"], candle[\"low\"], candle[\"close\"],\n",
    "                              candle[\"prev_close\"], candle[\"current_close\"], candle[\"volume\"]]])\n",
    "\n",
    "        # Feature Scaling\n",
    "        if allg.get(\"feature_scaling\", False):\n",
    "            if scaler is None:\n",
    "                raise ValueError(\"Scaler ist nicht gefittet! Bitte zuerst fit_scaler_on_training_data aufrufen.\")\n",
    "            features_scaled = scaler.transform(features)\n",
    "        else:\n",
    "            features_scaled = features\n",
    "\n",
    "        # Vorhersage\n",
    "        if not train_mode:\n",
    "            y_pred_prob = model.predict(features_scaled, verbose=0).flatten()[0]\n",
    "            pred_label = \"green\" if y_pred_prob > 0.5 else \"red\"\n",
    "        else:\n",
    "            y_pred_prob = 0.7  # Dummy für Offline\n",
    "            pred_label = \"green\" if y_pred_prob > 0.5 else \"red\"\n",
    "\n",
    "        actual_label = \"green\" if candle[\"color\"].lower() == \"green\" else \"red\"\n",
    "\n",
    "        # Profitberechnung\n",
    "        entry_price = candle[\"prev_close\"]\n",
    "        exit_price = candle[\"close\"]\n",
    "        direction = 1 if pred_label == \"green\" else -1\n",
    "        profit = (exit_price - entry_price) * direction\n",
    "        profit_percent = (profit / invested) * 100 if invested > 0 else 0\n",
    "\n",
    "        # Optional Strafe bei falscher Vorhersage\n",
    "        if train_mode and training_options.get(\"punish_on_wrong\", False):\n",
    "            if pred_label != actual_label:\n",
    "                profit *= 0.0\n",
    "\n",
    "        balance += profit\n",
    "\n",
    "        # Offline Training für jede Candle\n",
    "        if train_mode:\n",
    "            model.fit(features_scaled, np.array([1 if actual_label==\"green\" else 0]), epochs=1, verbose=0)\n",
    "\n",
    "        confidence = {\"green\": float(y_pred_prob), \"red\": float(1 - y_pred_prob)}\n",
    "\n",
    "        transactions.append({\n",
    "            \"timestamp\": candle[\"timestamp\"],\n",
    "            \"symbol\": candle.get(\"symbol\", \"BTCUSDT\"),\n",
    "            \"open\": candle[\"open\"],\n",
    "            \"high\": candle[\"high\"],\n",
    "            \"low\": candle[\"low\"],\n",
    "            \"close\": candle[\"close\"],\n",
    "            \"prev_close\": candle[\"prev_close\"],\n",
    "            \"current_close\": candle[\"current_close\"],\n",
    "            \"volume\": candle[\"volume\"],\n",
    "            \"balance_invested\": invested,\n",
    "            \"profit\": float(profit),\n",
    "            \"profit_percent\": float(profit_percent),\n",
    "            \"balance_after\": balance,\n",
    "            \"predicted\": pred_label,\n",
    "            \"actual\": actual_label,\n",
    "            \"confidence\": confidence\n",
    "        })\n",
    "\n",
    "    return transactions, balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa36db66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "# Vorbereitung: Scaler fitten\n",
    "# -------------------------------\n",
    "def fit_scaler_on_training_data(train_candles):\n",
    "    global scaler\n",
    "    if allg.get(\"feature_scaling\", False):\n",
    "        features_train = np.array([[c[\"open\"], c[\"high\"], c[\"low\"], c[\"close\"],\n",
    "                                    c[\"prev_close\"], c[\"current_close\"], c[\"volume\"]]\n",
    "                                   for c in train_candles])\n",
    "        scaler.fit(features_train)\n",
    "        print(\"Scaler erfolgreich gefittet.\")\n",
    "    else:\n",
    "        print(\"Feature Scaling ist deaktiviert. Kein Scaler benötigt.\")\n",
    "\n",
    "# -------------------------------\n",
    "# Haupt-Workflow: Training + Live\n",
    "# -------------------------------\n",
    "def run_trading_pipeline(initial_balance, period=\"7d\"):\n",
    "    global scaler, model\n",
    "    \n",
    "    balance = initial_balance\n",
    "    \n",
    "    # 1️⃣ Trainingsdaten abrufen\n",
    "    train_candles = fetch_train_data(period=period)\n",
    "    \n",
    "    # 2️⃣ Scaler fitten\n",
    "    fit_scaler_on_training_data(train_candles)\n",
    "    \n",
    "    # 3️⃣ Offline-Training durchführen\n",
    "    transactions_train, balance = prepare_transactions(train_candles, balance, train_mode=True)\n",
    "    print(f\"Offline-Training abgeschlossen. Balance nach Training: {balance:.2f}\")\n",
    "    \n",
    "    # 4️⃣ Live-Daten abrufen\n",
    "    live_candles = fetch_live_data()\n",
    "    \n",
    "    # 5️⃣ Live-Transaktionen vorbereiten (nur Analyse, Balance optional)\n",
    "    transactions_live, balance_live = prepare_transactions(live_candles, balance, train_mode=False)\n",
    "    print(f\"Live-Analyse abgeschlossen. Live-Balance: {balance_live:.2f}\")\n",
    "    \n",
    "    # 6️⃣ Speichern\n",
    "    json_path, csv_path = save_transactions(balance_live, transactions_live, model_path)\n",
    "    print(f\"Transaktionen gespeichert: JSON={json_path}, CSV={csv_path}\")\n",
    "    \n",
    "    return transactions_train, transactions_live, balance, balance_live\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7420998",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Startbalance\n",
    "balance = balance_settings[\"initial_balance\"]\n",
    "\n",
    "# 1️⃣ Trainingsdaten abrufen\n",
    "train_candles = fetch_train_data(period=\"7d\")\n",
    "\n",
    "# 2️⃣ Scaler fitten\n",
    "fit_scaler_on_training_data(train_candles)\n",
    "\n",
    "# 3️⃣ Offline-Training: train_mode=True\n",
    "transactions_train, balance_train = prepare_transactions(train_candles, balance, train_mode=True)\n",
    "\n",
    "# 4️⃣ Live-Daten abrufen\n",
    "live_candles = fetch_live_data()\n",
    "\n",
    "# 5️⃣ Live-Analyse: train_mode=False, eigene Balance\n",
    "transactions_live, balance_live = prepare_transactions(live_candles, balance, train_mode=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
